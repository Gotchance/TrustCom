Abstract
An increasing amount of malicious traffic from malware has recently been causing severe security incidents, making cyberspace less secure. It is known that some malware often displays synchronized behavior because specific actions are performed simultaneously by command & control servers or attackers. Our previous method monitors traffic arriving from darknets and detects the malicious cooperative activities of the sources of this traffic by using the graphical lasso, a well-known sparse learning algorithm. The method was effective but was unable to cope with real-time analysis because it relies on batch learning. In this study, we propose a method that captures anomalous cooperative behavior in real-time. At the same time, program processing time is shortened. To demonstrate the feasibility of the proposed method, a prototype was implemented, and several security incidents were detected by using real darknet traffic data. A performance evaluation was also conducted in terms of processing time and accuracy of security alerts to demonstrate the effectiveness and efficiency of the proposed method.

Ⅰ. Introduction
Threats in cyberspace have continued to grow and become diverse recently, and the number of variants and unknown attacks is increasing. The Network Incident Analysis Center for Tactical Emergency Response (NICTER) detects such detrimental incidents and threats on the Internet, and it releases information on threats and takes effective countermeasures. NICTER currently cooperates with organizations in about 40 countries, and it operates and monitors a large-scale black hole sensor on [a darknet | darknets?] of around 300,000 IP addresses to [determine | monitor?] the trend of malicious activities occurring on the Internet. Darknet refers to a set of accessible but unused subspaces of the Internet. A black hole sensor is a receiver (sensor) that collects packets without responding to senders of packets at all. Almost all packets reaching darknets originate from malicious activities. Darknets reflect global trends in malicious activities on the Internet, and a lot of research analyzes darknet traffic on the Internet.
In recent years, the traffic volume of our darknets and cyber-attacks has increased dramatically every year. Our organization has detected abnormalities [from | reported by?] NICTER by using a [heuristic rule-based | rule-based heuristic?], but the number of alerts is increasing, and the attacks are becoming diverse; consequently, it has become more difficult to detect alerts with the usual methods. Therefore, we worked on a method that uses machine learning and that can automatically detect anomalies with high accuracy.
Akiyama et al. defined three metrics for detecting botnets through analyzing their behaviors: relationship, response, and synchronization (cooperativeness). Among these metrics, we focused on the cooperative activities of malware that simultaneously operates on multiple hosts (devices) synchronously from darknet traffic. We devised a method for detecting malicious activities automatically from darknet traffic by estimating the cooperative relationships among hosts on the basis of an unsupervised machine learning method. Specifically, among the types of malware that perform cooperative actions, our detection targets are hosts that collaborate with infected devices with the same malware, such as worms, malicious scan activities, and exploit codes, to attack vulnerability. Moreover, infected devices with botnets that spread like worms targeting IoT devices, such as Mirai, Bashlite, and Hajime, are also targets of detection. As reported in paper [13], communications between infected devices are not required to detect [them | these targets?], so [it | our method?] can detect infected devices regardless of a C&C server's structures and protocols used.
In other words, [it | the method?] is effective even if botmasters change their C&C communication protocol and structure.
Also, it does not require payload information. Furthermore, since our method captures synchronous behaviors between hosts without supervisors and labeled data, irrespective of whether malware is known, even unknown attacks can be effectively detected if cooperative actions can be captured.
We briefly show the procedure of the method of our previous study below. [The input | One of the inputs?] of this method is the source host IP addresses observed during a certain period of traffic and the number of packets received by those hosts. Cooperative relationships among hosts are estimated by using the graphical lasso, which is well-known as a sparse structure learning algorithm. Finally, values obtained by quantifying the estimated cooperative relationships by using graph density are [an output | one of the outputs?]. Cases where the graph density value during a certain period is abnormally higher than other periods are determined as an alert. During these certain periods, it is judged that malicious activities have been made to the [destination port that has | destination ports that have?] the highest ratio of unique hosts among the period, and the hosts that sent packets to [that port | those ports?] are regarded as malicious hosts. This helps in investigating causes of malicious activities.
However, this method requires 3 days of traffic data as a sample for detection, so it needs [to store the traffic data of 3 days | to collect 3 days' worth of data?] before processing; hence, the detection will be delayed by 3 days at most, excluding the processing time. In other words, real-time detection is impossible. Since, in cybersecurity, cyberattacks must be detected as soon as possible to take prompt countermeasures, the impossibility of real-time processing is a great weak point. Accordingly, the main challenge of this paper is to enable this method for analyzing darknet traffic with machine learning to detect attacks in real-time.
 Contribution. This paper offers the following contributions:
1)	The previous work was effective but restrictive because its process was a batch learning type, which means that it could not be used for real-time analysis. Therefore, we propose a novel algorithm and a method for judging alerts for online processing.
2)	We reduce the computational cost through parameter tuning.
3)	We present several instances among the alerts obtained from our proposed method's continuous operation.

Ⅱ. Related Work
Many techniques have been studied for detecting [botnets via cooperative behavior | botnets that behave in cooperation?]. BotSniffer uses statistical algorithms to detect botnets in a centralized topology on the basis of their multiple crowd-like behaviors. BotMiner uses a detection framework that extends BotSniffer to perform clustering with monitored C&C communication and malicious activities, and it issues final detection results by cross-correlation. Garcia et al. applied a clustering algorithm to detect synchronization in bots and botnet behavior. This synchronization was studied for the relationship between IP addresses, ports, and time frames only. In this study, malware that performs coordinated malignant activities is detected by capturing cooperative relationships between hosts by using the graphical lasso.
Next, we investigated studies that used darknets as a data source. Many studies on darknets are ongoing.
Dainotti et al. proposed a methodology for removing spoofed traffic from both darknets and live networks and contributed to [the utilization inference | utilizing the inference?] of IP address spaces. Durumeric et al. analyzed a large-scale darknet to investigate scanning activities, disclosed large horizontal scan operations, and identified patterns in scanning operations. Fachkha et al. devised inference and characterization modules for extracting and analyzing cyber-physical systems (CPS) probing activities towards ample CPS protocols by correlating and analyzing various dimensions of a large amount of darknet data. Ban et al. proposed an abrupt-change detection algorithm that can detect botnet-probe campaigns with a high detection rate by exploring the temporal coincidence in botnet activities visible in darknets.
Finally, we devised another method to determine the cooperative relationships of hosts from darknets similar to the present method. Although our method estimates cooperative relations among hosts by using the graphical lasso algorithm, the method of Yamauchi et al. decomposes observed hosts into several host groups by using non-negative matrix factorization (NMF) and captures cooperative relationships. These two different methods differ in characteristics captured when capturing the cooperative relationship of the hosts, so the results may be different. [As we experienced in the past, it | It?] is known that the method of Yamauchi et al. is not suitable for small-scale data sources. However, our method can capture cooperative behaviors even for small-scale data sources.

Ⅲ. Previous Studies
In this section, we provide an overview of a graphical Gaussian model. Next, we present how to apply the model to darknet traffic data and present an outline of sparse structure learning with the graphical lasso algorithm. Finally, we describe the introduction of graph densities.

A.	Graphical Gaussian Model
Previous studies used the graphical Gaussian model (hereinafter referred to as the GGM), a basic model that expresses linear dependencies between variables in a graph. In the GGM, it is assumed that an N-dimensional random variable sequence \bm{x}=(x_{1},x_{2},\cdots,x_{N})^\mathrm{T} \in\mathbb{R}^N follows an N-dimensional multivariate Gaussian distribution. The distribution can be expressed as
\mathcal{N}({\bm{x}}|\mu,\Sigma)=\frac{\mathrm{det} (\Sigma^{-1})^{1/2}}{(2\pi)^{N/2}}\exp\left(-\frac{1}{2}(\bm{x}-\mu)^\mathrm{T}{\Sigma^{-1}}(\bm{x}-\mu)\right),
where \mu\in\mathbb{R}^N is the mean of \bm{x}, \Sigma\in\mathbb{R}^{N \times N} is a covariance matrix, and \Sigma^{-1}\in\mathbb{R}^{N \times N} is a precision matrix. Both a covariance matrix \Sigma and a precision matrix \Sigma^{-1} are symmetric positive definite matrices. Also, the determinant of a matrices A is written as \mathrm{det}(A).
Under the assumption of a multivariate Gaussian distribution, only when \Sigma^{-1}_{ij} is 0 can x_ {i} and x_ {j} be statistically independent, given other random variables. In other words, it can be expressed as follows.
\Sigma^{-1}_{ij}=0\Leftrightarrow x_i \perp x_j | \bm{x} \setminus \{ x_i, x_j \}.
For the Gaussian distribution, independence implies uncorrelatedness.
That is, \Sigma^{-1}_{ij}=0 indicates that there is no cooperative relationship between variables x_{i} and x_{j}.

B.	Applying GGM to Darknet Traffic Data
In this section, we present how to apply the GGM to darknet traffic data. When data is applied to the GGM, the length of the observation period used for one-model learning is set to T. For example, when 10 minutes of observed darknet traffic data is used for one-model learning, T refers to 10 minutes. Data observed in an interval of T is called a ``time slot.'' Fig. 1 shows an example of how a darknet traffic dataset is divided into time slots.
Next, packet data from N number of source hosts are recorded from darknet traffic data in a time slot.
At this time, the number of packets is counted for each source host, and the length of the time series is assumed to be M. The time series data of the number of packets per unit time (sampling interval) is then created. That is, in this case, M is the number of samples in a time slot, and the sampling interval is T/M.
The number of packets at the time of [m | M?] of the i-th source host is represented by y_i^{(m)}. Furthermore, since the number of packets is a nonnegative value, we take a logarithm to the variable x_i^{(m)}=\log(y_i^{(m)}) in order to make it similar to the Gaussian distribution. However as an exception, if y_i^{(m)}=0, x_i^{(m)} is set to \log0.1. That is, a time slot is converted to the following matrix.
D=[D_{im}]\in\mathbb{R}^{N \times M},\;\;D_{im} := x_i^{(m)}.

C.	Sparse Learning Using Graphical Lasso Algorithm
In this section, we introduce how to estimate the sparse precision matrix by using the graphical lasso. A sparse matrix refers to a matrix with few nonzero elements, and in sparse structure learning, a weak cooperative relationship is not an essential cooperative relationship. It is expected that essential cooperative relationships can be extracted by scraping them.
First, a sample covariance matrix S is obtained from input data (2), D. The sample covariance matrix S is substituted into the follow penalized maximize log-likelihood function with a \ell_1-regularization term based on the multivariate Gaussian distribution (1).
{\rm arg}\mathop{\rm max}\limits_{\Sigma^{-1} \succ 0} \left({\ln\mathrm{det}(\Sigma^{-1})}-\mathrm{Tr}(S\Sigma^{-1})-r||\Sigma^{-1}||_{1}\right),
where r is a positive real number.
The graphical lasso is an algorithm for solving (3) at high speed and with a high accuracy by using the block coordinate descent method. The graphical lasso is implemented as an R language package, ``glasso.'' Input arguments of ``glasso'' are the sample covariance matrix S and the regularization coefficient r, and the output is the sparsely estimated precision matrix \hat{{\Sigma}^{-1}}. In the graphical lasso, by adjusting the value of the regularization coefficient r, it is possible to adjust how much the precision matrix is estimated to be sparse. As the value of r increases, the precision matrix is estimated to be more sparse. From the above, it is possible to estimate a sparse precision matrix.

D.	Usage of Graph Densities
Ide et al. expressed cooperative relationships between source hosts as a graph by applying a GGM to traffic data. An undirected graph G = (V, E) has a node set V=\{x_{1}, \cdots, x_{N}\} and an edge set E=\{(i,j) \, | \, \Sigma^{-1}_{ij}\neq0\}. Each node corresponds to a random variable, and the existence of an edge between nodes indicates a presence or absence of a cooperative relationship between nodes (variables). In addition, in the analysis of darknet data, if a variable for the number of packets from a source host is made to correspond to a node, an undirected graph of the precision matrix shows the cooperative relationships between the source hosts.
Developing upon this idea, in our previous research, we proposed a novel criterion for judging abnormality by using graph density. Given G=(V,E), where the number of nodes in a graph is N(=|V|) and the number of edges is |E|, the graph density is defined as d=|E| \, / \, N(N-1). The graph density is the ratio of the actual number of edges to the number of edges of the complete graph. If the graph density value is higher than those in the other time slots, it is considered that there are more cooperative relationships between source hosts than in the other time slots. In our previous research, a statistical criterion for determining an abnormally high graph density value was determined, and abnormalities were detected effectively. At that time, a criterion for selecting the optimum regularization coefficient r was proposed.

Ⅳ. Proposed Method
The method of our earlier work is effective but restrictive because its process is a batch learning type, and [it may get alerts to be delayed for 3 days | its alerts may be delayed by 3 days | it may get alerts that are delayed by 3 days?] at maximum excluding the processing time. It cannot be used for real-time analysis. In this research, we extend our method to enable online processing and create an anomaly detection system to issue alerts in real-time. Fig. 2 shows an overview of the proposed method. Our approach was divided into four stages: preprocessing, model selection, quantification, and online processing & alert judgment. In this section, we introduce an alert judgment method and describe the online processing of anomaly-based detection with the method. Finally, we discuss an evaluation of processing time reduction.

A.	Alert Judgment Method for Online Processing
We considered an anomaly detection-based method for discriminating alerts during online processing. We could quantitatively quantize cooperative relationships among hosts in one time slot as a graph density. We aimed to automatically identify time slots with abnormally high graph densities compared with the graph densities of other time slots by online processing. For this purpose, we prepared graph densities of past K time slots from the current time slot as an object of comparison for anomaly-based detection and considered a method of judging whether a current calculated graph density of a time slot is abnormal.
The method is described as follows.
Let \bm{d} = (d_{1}, d_{2}, \cdots, d_{K}) be a sequence in which graph densities of obtained time slots are arranged in descending order. Next, let \bm{d}_{(i)} = (d_{i}, d_{i+1},\cdots,d_{K}), where i is a natural number. Let \sigma^{2}_{(i)} be a variance of elements of \bm{d}_{(i)}.
At this time, assume that the maximum i that satisfies \sigma^{2}_{(i+1)}/\sigma^{2}_{(i)}<\theta \, (0\leq \theta \leq 1) is i_{max} and set time slots corresponding to (d_{1},d_{2}, \cdots,d_{i_{max}}) as an alert. \theta is usually set to 0.95. Finally, we look for a destination port with the highest ratio of unique hosts among the time slots judged as alerts and examine the port protocol and the hosts that sent the packets to the destination port.
Also, the sparsity of [an estimated precision matrix from | a precision matrix that was estimated by?] the graphical lasso differs depending on the value of regularization coefficient r. That is, graph density values change in accordance with the value of r. In the batch processing method, only one optimum value of r was selected on the basis of input data. However, we believed that it is important to issue an alert rather than deciding the optimal value of r for online processing this time. In this method, instead of selecting only one value of r, we calculate the graphical lasso by setting several values of r in advance and issue an alert when the condition[s?] of an alert [is | are?] satisfied for at least one value of r.

B.	Algorithm for Online Processing
In this section, we outline the procedure for online processing. Suppose that there is a sequence \mathcal{D}=\{D_1, D_2, \cdots, D_K\} of data matrices obtained from a time series of time slots and a set d_{\mathcal{D}}^{(r)}=\{d^{(r)}_{D_1}, d^{(r)}_{D_2}, \cdots, d^{(r)}_{D_K}\} of K graph densities calculated from \mathcal{D} in advance. d^{(r)}_{D_i} (i \in \{1, 2, \cdots, K\}) is the graph density for each predetermined regularization coefficient r in the data matrix D_i.
It is assumed that the value of r is preset like r \in R ( =\{r_1, r_2, \cdots, r_s\} ). For example, preset R=\{0.2, 0.4, \cdots, 1.8\}. For online processing, the matrix of an updated time slot is given by D_t.
The pseudocode for online processing is described in Algorithm 1.
Note: Updating \mathcal{D} indicates that D_t is linked to \mathcal{D} and the oldest time slot in \mathcal{D} is deleted. Similarly, updating d_{\mathcal{D}}^{(r)} indicates that d_{D_t}^{(r)} is linked to d_{\mathcal{D}}^{(r)} and the oldest graph density in d_{\mathcal{D}}^{(r)} is deleted.
When updating \mathcal{D} and d_{\mathcal{D}}^{(r)}, each size is kept at K. In this way, the number of time slots used for determining an alert is fixed like a sliding window. With this procedure, an alert can be determined sequentially from the updated data, and the computation cost is reduced because only the graphical lasso needs to be calculated for the updated data.

C.	Processing Time
Since December 2017, we have been trial operating our proposed method continuously with darknet sensors located in 7 different places operated by NICTER. Table Ⅰ gives details on the IP address scales of each darknet sensor we used this time. In this section, we evaluate the processing time of the prototype. The specifications of the computer used for the evaluation, which was done at the Cybersecurity Laboratory, NICT, included 16 GB of memory and an Intel Xeon E3-1230 v3 3.30 GHz CPU. To perform real-time processing with limited resources, it is necessary to finish the current processing before updating the next time slot. The largest computational complexity of the program is the graphical lasso algorithm O(N^3). N is the number of source hosts in the processing target time slot.
Table Ⅱ shows the average and maximum value of the processing time and the number of source hosts when operated from December 2017 to March 2018. Parameter are set to T=10min.,\, M=6,\, K=432,\, \theta=0.95. As shown in Table Ⅱ, as the scale of the darknet sensor increases, N also increases, so we need to shorten the processing time. Since sensors F and G are actually large in scale, we decided to shorten the processing time by considering the following measures.
･ Restrict the regularization coefficient, r.
･ Ignore the third and fourth octets of IP addresses of source hosts.
･ Select source hosts uniformly at random and limit the number of nodes, N.
[Restring | Restricting?] r refers to reducing the number of its elements. Ignoring octets means that IP addresses on the same subnet are regarded as one host. Limiting the number of source hosts N indicates [when N exceeds the limit number | that N cannot exceed a certain limit?]. Since characteristics of darknet traffic vary depending on its scale and the country in which the sensor is located, it is necessary to periodically adjust the above-mentioned parameters to be limited for each darknet. [Actually, in | In fact, in | As can be seen in?] Table Ⅱ, we set sensors A to E to r=\{0.2, 0.4, \cdots, 1.8\}, \, octet=4 and sensors F and G to r=\{0.6, 0.8, \cdots, 1.8\}, \, octet=2\sim3, \, limitation\_N = 1000. We regularly adjusted the parameters so that online processing would be on time. In addition, if the processing time of a time slot exceeded 900 seconds, the processing was forcibly terminated.

Ⅴ. Case Studies
A.	Preprocessing of Data
In this study, we collected only TCP packets to which a SYN flag was attached. As a feature of black hole sensors on darknets, packets except for SYN such as SYN-ACK, ACK, and RST are often backscatters, and we ignored those packets since they are not our detection target. In addition, we pre-excluded packets arriving from known scanners that are for research and investigation purposes. When a large number of packets constantly arrive at a specific TCP port, or when packets are constantly arriving from many hosts, those TCP ports are excluded. In addition, we expected to get [an unknown vulnerable TCP port as an alert | an alert for an unknown vulnerable TCP port?] by excluding known fragile TCP ports [that we have frequently obtained as alerts | for which we have frequently obtained alerts?]. We intentionally excluded those ports considering the possibility that other cooperative activities would be buried. Our goal is not only to detect known attacks but also to detect unknown attacks. The detection of unknown attacks increases when constantly targeted or known fragile ports are excluded in advance. In operation from December 2017 to March 2018, TCP ports 22, 23, 80, 443, 445, 1433, 2323, 3389, 5358, and 7547 were excluded from the preprocessing.

B.	Summary of Alert Results
Table Ⅲ shows a monthly alert summary. We ignored alerts with a ratio of unique hosts numbering less than 10\% and a number of unique hosts less than 50. In addition, we divided priority into 10\% and 40\%. In the case of alerts obtained only about once or twice, this was often due to a temporary [host increase | increase in the number of hosts?], and, for many cases, it was difficult to investigate the cause. Table Ⅳ show an alert summary for each sensor. We did not get alerts for A and B with a small sensor scale. Sensors C, D, and E had important events, but temporary events were also acquired as alerts. For sensors F and G, alert port types were relatively small compared with other sensors, but they were often an important event. In the following, we introduce instances of actual new trending attacks that could be known from these alerts.

1)	Detection Instances Related to ADB Miner (5555/TCP)
We present detection instances of activities related to a mining botnet utilizing Android Debug Bridge (ADB). Fig. 3 shows a chronological chart of the number of unique hosts observed across our all darknets per 1 day. On February 4, 2018, TCP port 5555 was seen to have a rapidly increasing number of unique hosts. We detected this in a timely manner. Details on the alerts obtained are given below. 
The following items are related to 5555/TCP. ADB.Miner, a mining botnet utilizing ADB was spreading via 5555/TCP. It was seen in a large quantity from February 4, and about 16,000 hosts could be seen at the peak from NICTER's darknets. Since then, the attack[s?] [continued | has continued | have continued?] while maintaining its scale. According to a Netlab 360 report, they detected the attack[s?] at 15:00 on February 3 (GMT +8) with their system, and the earliest time that the infection could be traced back to was January 31. It infects when 5555/TCP (ADB debugging interface) is open, and its target is mainly Android devices.
･ Worm infection: Infected devices will initiate a network scan on 5555/TCP and attempt to execute ADB commands [as a newly infected worm?].
･ XMR Mining: After infection, it will dig XMR tokens.
In addition, this worm borrows code from Mirai's SYN scanning module for efficiency. This is the first case of seeing Mirai's code on Android bots. In the case of Japan, there were many infections when using Android devices from overseas manufacturers and a specific mobile SIM card.

2)	Detection Instances Related to Hajime Variants (8291, 2000/TCP)
We introduce detection instances of activities related to Hajime botnet variants. Fig. 4 shows a chronological chart of the number of unique hosts observed across all of our darknets per 1 day. On March 25, 2018, TCP port 8291 was seen to have a rapidly increasing number of unique hosts, and, also, on March 31, 2018, TCP port 2000 was seen to have a rapidly increase in the same way. We detected these in a timely manner. Details on the alerts related to TCP ports 8291 and 2000 are given below.
The scanning events of TCP ports 8291 and 2000 were caused by a Hajime botnet variant targeting the vulnerabilities of router products manufacturer ``X.'' 8291/TCP increased sharply from March 25, but attacks with the same behaviors moved from March 31 to 2000/TCP. As a feature of Hajime, C&C communication using BitTorrent's P2P protocol is performed and supports only ARM and MIPS architectures. Also, the source code is not published, and there are few variants. If TCP ports 8291 or 2000 are open, [it | the botnet variant?] tries to infect by accessing common web ports 80, 81, 82, 8080, 8081, 8082, 8089, 8181, and 8880. It exploits known vulnerabilities of the operating systems of routers [ChimayRed HTTP exploit, SMB buffer-overflow vulnerability (CVE-2018-7445)] as well as password brute-forcing.

Ⅵ. Conclusion
We proposed a method for detecting coordinated malignant activities from darknets in real-time by using the graphical lasso and an alert judgment method that uses graph density. The methods were put to practical use with real darknet traffic. The processing time was shortened, and parameter tunings were evaluated. We were able to show alert summaries and introduce instances of attacks related to ADB Miner and Hajime variants.
Since almost all packets reaching darknets originate from malicious activities, there is no correct or incorrect answer for attacks. Moreover, we do not know the cause of most of them. In other words, even if we catch cooperative relationships from darknet traffic by using this method, we cannot evaluate accuracy unless we know the cause. As future work, we would like to quantitatively evaluate accuracy. An alert for which the cause is known would be judged as a correct answer, and those for which the cause is unknown would be judged as a false-positive. A global attack that could not be detected with this method would be judged to be false-negative. We will determine the optimal parameters automatically for each darknet to obtain alerts regardless of the scale in our next step. In addition, [filtering ports in preprocessing were | the filtering of ports was?] done manually until now, but automatic preprocessing is also part of our future work.
