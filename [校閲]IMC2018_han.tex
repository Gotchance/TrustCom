\documentclass[letterpaper]{sig-alternate-10pt}
\setlength{\paperheight}{11in}
\setlength{\paperwidth}{8.5in}

%\usepackage[pass,]{geometry}
\usepackage[dvipdfmx]{color}
\usepackage{epsfig,endnotes}
\usepackage{amssymb,amsmath,amssymb,bm,txfonts}
\usepackage{enumerate,fancybox,url,ascmac,here,comment,wrapfig}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{authblk}
\begin{document}

\title{Real-time Detection of Malicious Cooperative Behaviors\\by the Graphical Lasso from Darknet Traffic}

%for single author (just remove % characters)
\author[1, 2]{\large Chansu Han}
\author[3]{\large Jumpei Shimamura}
\author[2]{\large Takeshi Takahashi}
\author[2]{\large Daisuke Inoue}
\author[1]{\large Masanori Kawakita}
\author[1, 2]{\large \\Jun'ichi Takeuchi}
\author[2]{\large Koji Nakao}

\affil[1]{Kyushu University}
\affil[2]{National Institute of Information and Communications Technology}
\affil[3]{Clwit Inc.}


\maketitle

\begin{abstract}
An increasing amount of malware recently incurs severe security incidents, making cyberspace less secure.
Malware needs to be detected.
It is known that malware often presents synchronized behavior, because a command \& control server may instruct bot computers to perform a specific action simultaneously.
Our earlier work monitors traffic arriving in darknet spaces and detects synchronized activities of the traffic sources by using {\it graphical lasso}, a well-known sparse learning algorithm.
The method was effective but was unable to cope with real-time analysis because it relies on batch learning.
In this study, the method is extended so as to capture anomalously cooperative behaviors in real-time.
At the same time, program calculation time is shortened, and parameters are tuned to improve security alert accuracy.
To demonstrate the feasibility of the proposed method, a prototype was implemented and several security incidents were detected using real traffic data.
A performance evaluation was also conducted in terms of calculation time and accuracy of security alerts to demonstrate the effectiveness and efficiency of the proposed method.
\end{abstract}

\keywords{Botnet, Malware, Darknet, Real-time Detection}


\section{Introduction}
Since 2003, botnets have become a significant threat to cybersecurity on the Internet~\cite{McCarty}.
The threat has continued to change and develop recently and the number of variants and unknown attacks are increasing.
Botnets are networks made up of computers called ``bots'' remote-controlled by a human operator called a ``botmaster'' using command \& control servers (hereinafter referred to as a C\&C server).
Akiyama {\it et al.} defined three metrics for detecting botnets through analyzing their behaviors: relationship, response, and synchronization~\cite{Akiyama}.
Among these metrics, we focused on cooperative activities of malware that simultaneously operates on multiple hosts (devices) synchronously.

The National Institute of Information and Communications Technology (NICT) in Japan monitors and logs the darknet traffic of around 300,000 IP addresses as datasets by international collaboration~\cite{NICTERWEB} and we used parts of these datasets in our work.
The darknet refers to a set of accessible but unused subspaces of the Internet.
Almost all packets reaching darknets originate from malicious activities.
Darknets reflect global trends in malicious activities of the Internet, and a lot of research analyzes darknet traffic on the Internet~\cite{Ali, Bailey, Bailey2, Ban, Choi, Nakao}.
In recent years, the traffic volume of our darknet has increased dramatically every year.
There is a limit to check and operate manually one by one whether this traffic is caused by malware or not (e.g., misconfiguration).
In addition, heuristic rule detection methods often involve many constraints.

Therefore, we developed a method to detect malicious activities by estimating cooperative relationships among hosts using unsupervised machine learning method~\cite{Han}.
Specifically, among the types of malware that perform cooperative actions, botnets are mainly the detection target, and hosts that collaborate with infected devices with the same malware such as a worm and malicious scan activities are also subject to detection.
In general, botnets communicate with each other using HTTP, IRC, P2P, and other generic protocols.
However, our method~\cite{Han} does not require communication between bots to detect them, as it can detect a botnet regardless of C\&C server's structures and protocols used.
It is effective even if botmasters change their C\&C communication protocol and structure.
Also, this method does not require payload information.
Furthermore, since our method captures the synchronous behaviors between hosts without supervisors and labeled data, irrespective of whether malware is known, even unknown attacks can be effectively detected if cooperative actions can be captured.

However, a real-time detection was impossible and the method needs to store traffic data for three days before it begins the process, so the detection may be delayed by three days at maximum excluding the processing time.
Due to a characteristic of cybersecurity that must grasp cyberattacks as soon as possible and take countermeasures, the impossibility of real-time processing is a great weak point.
Accordingly, the main challenge of this paper is to enable this darknet traffic analysis method using machine learning to be detected in real-time.


\vspace*{0.3 cm}
\noindent
\textbf{Approach.}\space\space
Most of the packets reaching a darknet are abnormal, but the volume of traffic is so numerous that there is a limit to managing and operating everything.
For the purpose of extracting only important and big events among them, we focused on the property that a botnet synchronizes with hosts, as mentioned above.
Our approach was divided into 4 stages: preprocessing, model selection (graphical Gaussian model and sparse structure learning using the graphical lasso), quantification, anomaly detection \& alert issuance.
First, we pre-processed raw packet data of darknet traffic and proceed to model selection.
Second, we applied the graphical Gaussian model to darknet traffic under the assumption that darknet traffic follow a Gaussian distribution.
Then, we performed a maximum likelihood estimation with $\ell_1$-regularization term using the graphical lasso, which is a well-known sparse structure learning algorithm for the graphical Gaussian model~\cite{Friedman}.
That estimated the presence or absence of cooperative relationships between source hosts~\cite{Hamasaki}.
Third, as a stage of quantification, we represented the estimated cooperative relationships between hosts as an undirected graph~\cite{Mukai2}, and we quantified cooperative relationships using graph density.
Finally, we issued alerts by anomaly-based alert judgment method~\cite{Han}.
Alerts are the time periods where the number of synchronized hosts is abnormally high.
Then, we investigated types of information such as headers and payloads of packets and examine the type of attacks manually.


\vspace*{0.3 cm}
\noindent
\textbf{Contribution.}\space\space
This paper offers the following contributions:
\begin{enumerate}
	\item The previous work~\cite{Han} was effective but restrictive because its process was a batch learning type, which means that it could not be used for real-time analysis.
Therefore, we proposed a new algorithm and an alert judgment method for online processing.

	\item The implemented analysis engine has been running continuously at NICT since September 2017.

	\item We optimized detection accuracy and computational cost through parameter tuning.

	\item We present a number of instances of interest among the alerts obtained from our proposed method's continuous operation.
\end{enumerate}

\vspace*{0.3 cm}
\noindent
\textbf{Roadmap.}\space\space
We first provide readers with a background on darknets in Section 2.
In Section 3, we introduce related works from three perspectives: related surveys, studies using darknets, and studies via cooperative behaviors.
In Section 4, we present previous studies in the order of outline of the graphical Gaussian model, how to apply the graphical Gaussian model to darknet traffic data, an introduction to sparse structure learning using the graphical lasso algorithm, a presentation of criteria for determining botnets, and usage of graph densities.
In Section 5, we propose a new method for alert judgments and an online processing algorithm.
The implementation of a prototype, consideration of calculation time, and evaluations of parameter tunings are also provided in this section.
In Section 6, we show detected instances from our method's continuous operation.
Finally, we conclude in Section 7.

\section{Darknet}
In this section, we introduce the background on the darknet and details about collected datasets.
As illustrated in Figure~\ref{fig:darknet}, the darknet refers to a set of accessible but unused subspaces of the Internet.
These subspaces are ``unused'' as they are not connected to any devices.
In theory, any packets should not arrive at darknets because they are not connected to any devices.
However, in fact, quite few packets do arrive.
Almost all packets reaching darknets are caused by malicious activities.
Types of packets include scans and attacks by malware, backscattering (a reflection of DDoS attack), results of misconfiguration, etc.
Darknet traffic reflect global trends in malicious activities on the Internet (particularly the status of worm-type malware infections)~\cite{CyberLab}.
In other words, by analyzing darknet traffic, it is possible to capture trends of cyberattacks and malware infections in real-time.
Accordingly, darknets are very useful to observe the behavior of serious attacks over the Internet.


\begin{figure}[tb]
\begin{center}
	\includegraphics[width=8.0cm,clip]{./Materials/darknet.eps}
	\caption{An outline of darknet}
  	\label{fig:darknet}
\end{center}
\end{figure}


In the present work, we use darknet traffic monitored and logged by NICT.
We aim for our results (alerts) to be adopted in the Network Incident Analysis Center for Tactical Emergency Response (NICTER) as an automatic analysis system~\cite{NICTERWEB, Nakao}.
The purpose of NICTER is that it enables the early detection of such incidents, which are detrimental to networks, and determines the quickest and most effective countermeasures.
Darknets observed by NICTER are spread in various countries through international collaboration, and the scale of observation is about 300,000 IP addresses in 2017.
Darknet sensors, operated by NICT, are located in different about 40 countries and organizations, and the scale of IP addresses monitored by each sensor is from 2 to 65,536.
Each sensor has different IP subnets (IP network parts), and one sensor belongs to almost the same subnet.
Table~\ref{tab:packet} shows number of packets observed by NICTER.
As seen from Table~\ref{tab:packet}, the traffic volume of NICTER's darknets has increased dramatically.
In 2017, the total of observation packets per one IP address was 559,125 packets combined with TCP and UDP protocols from NICTER's 300,000 darknet observation IP addresses.
Over 600 million TCP packets were observed a day at its peak.
Furthermore, the number of unique source host IP addresses for TCP packets varied in the range of approximately 700,000 to 3 million IP addresses per day.
In this proposed method, we collected TCP packets with the SYN flag attached and obtained the following information from each darknet packet: transmission time, a source IP address, a destination IP address, and a destination port number.

\begin{table}[htb]
  \begin{center}
    \caption{Number of packets observed by NICTER}
    \begin{tabular}{cccc} \hline
       & Total packets & Observation & \\
      Year & per year & IP addresses & Annual total packets \\
       & (billion) & (about) & per one IP address \\ \hline \hline
      2005 & 0.31 & 16,000 & 19,066 \\
      2006 & 0.81 & 100,000 & 17,231 \\
      2007 & 1.99 & 100,000 & 19,118 \\
      2008 & 2.29 & 120,000 & 22,710 \\
      2009 & 3.57 & 120,000 & 36,190 \\
      2010 & 5.65 & 120,000 & 50,128 \\
      2011 & 4.54 & 120,000 & 40,654 \\
      2012 & 7.78 & 190,000 & 53,085 \\
      2013 & 12.88 & 210,000 & 63,655 \\
      2014 & 25.66 & 240,000 & 115,323 \\
      2015 & 54.51 & 280,000 & 213,523 \\
      2016 & 128.1 & 300,000 & 469,104 \\
      2017 & 150.4 & 300,000 & 559,125 \\ \hline
    \end{tabular}
    \label{tab:packet}
  \end{center}
\end{table}


\section{Related Work}
We reviewed surveys of related research on botnet detection.
In~\cite{Garcia} the characteristics of network-based botnet detection technology are classified into three main classes: detection algorithms, detection techniques, and detection sources.
When applying our method to these classifications, we used the graphical lasso, which is an unsupervised algorithm, and heuristic rules for the detection algorithm, an anomaly-based technique featuring the behavior of bots for the detection technique, and darknet traffic as the detection source.
According to~\cite{Garcia}, all the papers surveyed had used heuristic-based rules at some point in the analysis.

In~\cite{Feily}, botnet detection approaches were compared on the basis of five key features: the ability to detect unknown bots, the capability of botnet detection regardless of botnet protocol and structure the ability to detect botnets with encrypted C\&C channels, real-time detection, and overall accuracy.
When comparing our method against these features, it can detect unknown bots and it does not depend on botnet protocol and structure as mentioned in the Introduction.
Also, it does not require access to C\&C payloads for detection, so it does not matter if the botnets have encrypted C\&C channels, and real-time detection is the main contribution of our method.
However, evaluating the accuracy is difficult because most darknet traffic does not have payload data, attack codes cannot be collected, and it is difficult to label.
Although we increased the accuracy of alerts by using a heuristic method based on empirical experiments, we can not express the accuracy quantitatively at this time.
Therefore, an evaluation of the accuracy remains as a future work.

We investigated studies that used darknets as a data source.
Many studies using darknets to research countermeasures against malicious activities are ongoing.
These can be classified into two categories, managing and designing darknet platforms and darknet analysis.
Bailey {\it et al.} introduced the Internet Motion Sensor (IMS), to measure, characterize and track threats~\cite{Bailey, Bailey2}.
Choi {\it et al.} proposed a security monitoring and response model to analyze cyberthreats trend and to trace potential attackers~\cite{Choi}.
NICTER is also a study about darknet platforms~\cite{Nakao}.
Under darknet analysis, since three-way handshaking is not performed on darknet traffic and there is almost no payload data, most of the botnet detection techniques targeted for real network traffic can not usually be applied in a darknet.
Therefore, a new method for darknet analysis is necessary.
Ali {\it et al.} classified DDoS attacks by using Resource Allocating Network with Locality Sensitive Hashing (RAN-LSH) in which data to be trained are selected by using LSH, and fast online learning is actualized by training only selected data~\cite{Ali}.
Ban {\it et al.} proposed an abrupt-change detection algorithm that can detect botnet-probe campaigns with a high detection rate by exploring the temporal coincidence in botnet activities visible in darknets~\cite{Ban}.

Many techniques have been studied for detecting botnets via cooperative behaviors.
BotSniffer uses statistical algorithms to detect botnets in a centralized topology on the basis of their multiple crowd-like behaviors~\cite{Gu}.
BotMiner uses a detection framework that extends BotSniffer to perform clustering with monitored C\&C communication and malicious activities, respectively, and issue final detection results by cross-correlation~\cite{Gu2}.
Strayer {\it et al.} proposed a temporal correlation algorithm on packet inter-arrival time and packet size in a five-dimensional space~\cite{Strayer}.
Garc\'{i}a {\it et al.} applied an EM clustering algorithm to detect synchronization in bots and botnets behavior~\cite{Garcia2}. This synchronization was studied as the relationship between IP addresses, ports, and time frames only.

As with our method, there has been research that characterizes synchronism from darknet traffic.
Yamauchi {\it et al.} proposed a method for botnet detection from darknet traffic by the non-negative matrix factorization (NMF), which can decompose the vector valued time series data into several components~\cite{Yamauchi}.
Compared with Yamauchi {\it et al.}, our method has a higher computational cost, but is applicable even when the data size is small with a small scale of observation of the darknet.


\section{Previous Studies}
In the method proposed by Hamasaki {\it et al.}~\cite{Hamasaki}, malware activities (botnets) were detected by capturing change points in cooperative relationships between source hosts of darknet traffic data from properties such as cooperativeness (synchronization) in botnet host groups.
An anomaly detection was performed by using the Kullback-Leibler divergence to capture change points.
Mukai {\it et al.}~\cite{Mukai1} extended Hamasakit {\it et al.}'s method by using a moving average score.
These cooperative relationships between source hosts were expressed as a graph by applying the graphical Gaussian model to traffic data~\cite{Ide}.
In another paper by Mukai {\it et al.}~\cite{Mukai2}, a method for detecting abnormality by visualizing a graph was proposed.

In this section, we provide an overview of the graphical Gaussian model.
Next, we present how to apply the model to darknet traffic data and present an outline of sparse structure learning using the graphical lasso algorithm.
Finally, we introduce criteria for determining botnets in the previous studies using an estimated precision matrix, and the usage of graph densities.

\subsection{Graphical Gaussian Model}
These studies used the graphical Gaussian model (hereinafter referred to as the GGM), a basic model that expresses linear dependencies between variables in a graph.
In the GGM, it is assumed that a $N$-dimensional random variable sequence $\bm{x}=(x_{1},x_{2},\cdots,x_{N})^\mathrm{T}\in\mathbb{R}^N$ follows the $N$-dimensional multivariate Gaussian distribution.
The multivariate Gaussian distribution can be expressed as
\begin{equation*}
\mathcal{N}({\bm{x}}|\mu,\Sigma)=\frac{\mathrm{det} (\Sigma^{-1})^{1/2}}{(2\pi)^{N/2}}\exp\left(-\frac{1}{2}(\bm{x}-\mu)^\mathrm{T}{\Sigma^{-1}}(\bm{x}-\mu)\right),
\end{equation*}
where $\mu\in\mathbb{R}^N$ is the mean of $\bm{x}$, $\Sigma\in\mathbb{R}^{N \times N}$ is a covariance matrix, and $\Sigma^{-1}\in\mathbb{R}^{N \times N}$ is a precision matrix.
Both a covariance matrix $\Sigma$ and a precision matrix $\Sigma^{-1}$ are symmetric positive definite matrix.
Also, the determinant of a matrices A, written $\mathrm{det}(A)$.

Under the assumption of the multivariate Gaussian distribution, only when $\Sigma^{-1}_{ij}$ is ​​0, then $x_ {i}$ and $x_ {j}$ are statistically independent, given other random variables.
In other words, it can be expressed as follows.
\begin{equation*}
\Sigma^{-1}_{ij}=0\Leftrightarrow x_i \perp x_j | \bm{x} \setminus \{ x_i, x_j \}.
\end{equation*}
For the Gaussian distribution, independence implies uncorrelatedness.
That is, $\Sigma^{-1}_{ij}=0$ indicates that there is no cooperative relationship between variables $x_{i}$ and $x_{j}$~\cite{Ide}.
In such a GGM, an undirected graph $G = (V, E)$ has a node set $V=\{x_{1}, \cdots, x_{N}\}$ and an edge set $E=\{(i,j)|\Sigma^{-1}_{ij}\neq0\}$.
Each node corresponds to a random variable, and the existence of an edge between nodes indicates a presence or absence of a cooperative relationship between nodes (variables).
Although all of the diagonal components of an actual precision matrix $\Sigma^{-1}$ are positive real numbers, all diagonal components are set to 0 for graph representations.
In addition, in the analysis of darknet data, if a variable for the number of packets from a source host is made to correspond to a node, an undirected graph of the precision matrix shows the cooperative relationships between the source hosts.
Figure~\ref{fig:graph1} are examples of undirected graphs obtained from applying the GGM to real darknet traffic data.

\begin{figure}[htbp]
\begin{tabular}{c}
	\begin{minipage}{0.5\hsize}
		\includegraphics[width=4cm,clip]{./Materials/undirected_graph1.png}
 	\end{minipage}
 	\begin{minipage}{0.5\hsize}
		\includegraphics[width=4cm,clip]{./Materials/undirected_graph2.png}
 	\end{minipage}
\end{tabular}
\caption{Examples of undirected graph}
\label{fig:graph1}
\end{figure}


\subsection{Applying the GGM to Darknet Traffic Data}
In this section, we present how to apply the GGM to darknet traffic data.
When the data is applied to the GGM, the length of observation period used for an one model learning is set to $T$.
For example, when 10 minutes of observed darknet traffic data is used for one-model learning, $T$ refers to 10 minutes.
Data observed in an interval of $T$ is called a time slot.
Figure~\ref{fig:timeslot} shows an example of how the darknet traffic dataset is divided into time slots.

\begin{figure}[htbp]
	\includegraphics[width=8.0cm,clip]{./Materials/timeslot.eps}
	\caption{Darknet traffic dataset divided into time slots $(T={\rm 10 min.})$}
  	\label{fig:timeslot}
\end{figure}

Next, packet data from $N$ number of source hosts are recorded from darknet traffic data in a time slot.
At this time, the number of packets is counted for each source host, and the length of the time series is assumed to be $M$.
The time series data of the number of packets per unit time (sampling interval) is then created.
That is, in this case, $M$ is the number of samples in a time slot and the sampling interval is $T/M$.
The number of packets at the time of $m$ of the $i$ th source host is represented by $y_i^{(m)}$.
Furthermore, since the number of packets is a nonnegative value, we take a logarithm to the variable $x_i^{(m)}=\log(y_i^{(m)})$ in order to make it similar to the Gaussian distribution.
However as an exception, if $y_i^{(m)}=0$, $x_i^{(m)}$ is set to $\log0.1$.
That is, a time slot is converted to the following matrix.
\begin{equation}
\label{eq:d}
D=[D_{im}]\in\mathbb{R}^{N \times M},
\;\;D_{im} := x_i^{(m)}.
\end{equation}


\subsection{Sparse Structure Learning Using \\the Graphical Lasso Algorithm}
In this section, we introduce how to estimate the precision matrix by the graphical lasso.
The most natural way to estimate the precision matrix $\Sigma^{-1}$ is to do a maximum likelihood estimation, which has been studied significantly in the past~\cite{Dempster, Meinshausen}.
Under the assumption of the multivariate Gaussian distribution, the maximum likelihood solution of the precision matrix $\Sigma^{-1}$ is an inverse matrix of the sample covariance matrix $S$.
However, a maximum likelihood estimator of the precision matrix $\Sigma^{-1}$ is usually a dense matrix, and its estimation accuracy is poor.
In addition, if strongly correlated variables exist, there is a problem that the inverse matrix of the sample covariance matrix $S^{-1}$ causes a rank deficient, and the inverse matrix will not even exist.

Although many methods to avoid this problem have been studied, Hamasaki {\it et al.} considered sparse structure learning that can estimate the precision matrix to sparse using the graphical lasso~\cite{Friedman}.
A sparse matrix refers to a matrix with few nonzero elements, and in sparse structure learning, a weak cooperative relationship is not an essential cooperative relationship.
It is expected that essential cooperative relationships can be extracted by scraping them.

The flow of sparse structure learning by the graphical lasso is shown below.
The penalized maximum likelihood equation is solved with a $\ell_1$ regularization term based on the multivariate Gaussian distribution.
First, a sample covariance matrix $S_{ij}$ is obtained from the data $D$, equation~(\ref{eq:d}).
\begin{equation}
\label{eq:s}
S_{ij}=\frac{1}{M}\sum_{m=1}^{M}(x_{i}^{(m)}-\mu_{i})(x_{j}^{(m)}-\mu_{j}),
\end{equation}
where $i$ and $j$ are natural numbers from 1 to $N$ and $\mu_i$ is a sample mean of $x_i$.
The sample covariance matrix $S$ is substituted into the follow log-likelihood function.
\begin{equation*}
\mathrm{ln}{\prod_{m=1}^{M}}{N(\bm{x}^{(m)}|\mu,\Sigma)}=\mbox{const.}+\frac{M}{2}\left\{{\ln\mathrm{det}(\Sigma^{-1})}-\mathrm{Tr}(S\Sigma^{-1})\right\}.
\end{equation*}
The penalized maximize log-likelihood function with a $\ell_1$-regularization term in the form
\begin{equation}
\label{eq:max}
{\rm arg}\mathop{\rm max}\limits_{\Sigma^{-1} \succ 0} \left({\ln\mathrm{det}(\Sigma^{-1})}-\mathrm{Tr}(S\Sigma^{-1})-r||\Sigma^{-1}||_{1}\right),
\end{equation}
where $r$ is a positive real number and $\|\Sigma^{-1}\|_{1}$ is a $\ell_1$-norm of $\Sigma^{-1}$ defined as
\begin{equation*}
	\|\Sigma^{-1}\|_{1}={\sum_{ij}^{N}}|(\Sigma^{-1})_{ij}|.
\end{equation*}

The graphical lasso is an algorithm to solve Equation~(\ref{eq:max}) at high speed and with a high accuracy using the block coordinate descent method~\cite{Banerjee}.
The graphical lasso is implemented as an R language package ``glasso.''
Input parameters (arguments) of ``glasso'' are the sample covariance matrix $S$ and the regularization coefficient $r$, the output is the sparsely estimated precision matrix $\hat{\Sigma}^{-1}$.
In the graphical lasso, by adjusting the value of the regularization coefficient $r$, it is possible to adjust how much the precision matrix is estimated to sparse~\cite{Tibshirani}.
As the value of $r$ increases, the precision matrix is estimated to be more sparse.
From the above, it is possible to estimate the sparse precision matrix and obtain undirected graphs of the GGM.

\subsection{Criteria for Determining Alerts}
In Hamasaki {\it et al.}'s method, change points of the estimated precision matrix from before and after each time slot were obtained to determine botnets.
Kullback-Leibler divergence is used as a measure of change points.
It measures the difference between two probability density functions $p(x)$ and $q(x)$, and is defined as
\begin{equation}
\label{eq:KL}
\mathrm{D_{KL}}(p||q)=\int^{\infty}_{-\infty}{p(x)}\mathrm{log}\frac{p(x)}{q(x)}\mathrm{d}x.
\end{equation}
For a certain time slot, the estimated distribution at time $t_{0}$ is set to $p$, the estimated distribution for one time slot before time $t_{1}$ is set to $q$.
Change points of the distribution generated in a time series are quantified by the above Kullback-Leibler divergence.
Since $p$ and $q$ follow the multivariate Gaussian distribution, Equation~(\ref{eq:KL}) is expanded as follows
\begin{equation*}
\begin{split}
\mathrm{D_{KL}}(p||q) &= s(t_{0}) = \int{p(\bm{x})}\mathrm{log}{p(\bm{x})}\mathrm{d}\bm{x}-\int{p(\bm{x})}\mathrm{log}{q(\bm{x})}\mathrm{d}\bm{x}\\
	&= \frac{1}{2}(\mathrm{log}|\Sigma_{q}|-\mathrm{log}|\Sigma_{p}|+\mathrm{Tr}|\Sigma^{-1}_{q}\Sigma_{p}|)\\
	&\quad+\frac{1}{2}(\bm{\mu_{p}}-\bm{\mu_{q}})^{\mathrm{T}}\Sigma^{-1}_{q}(\bm{\mu_{p}}-\bm{\mu_{q}})-\frac{N}{2}.
\end{split}
\end{equation*}
From this, the score $s(t_{0})$ is obtained in chronological order.
$\tilde{\mu}(t_{20}^{0})$ is set to an average from time $t_{0}$ to $t_{20}$, $\tilde{\sigma}(t_{20}^{0})$ to a standard deviation, and $\tilde{\mu}(t_{20}^{0})+2\tilde{\sigma}(t_{20}^{0})$ to a threshold.
When $s(t_{0})>\tilde{\mu}(t_{20}^{0})+2\tilde{\sigma}(t_{20}^{0})$ is satisfied, it is judged that a botnet is active at $t_{0}$, and an alert is issued.

Hamasaki {\it et al.} had a problem in that the false alert rate was high for their botnets judgment method.
To solve this problem, Mukai {\it et al.} improved Hamasaki {\it et al.}'s method using a moving average score as a criterion for issuing alerts.
The moving average score is defined as
\begin{equation*}
\bar{s}(t_{0}(n))=\frac{s(t_{n})+\cdots+s(t_{1})+s(t_{0})}{n}.
\end{equation*}
By using a moving average score, it is not distracted by temporary fluctuations of data, and tends to grasp change trends of the whole data~\cite{Falt}.
$\tilde{\mu}(t_{25}^{10})$ is set to an average from time $t_{25}$ to $t_{10}$, $\tilde{\sigma}(t_{25}^{10})$ to a standard deviation, and $\tilde{\mu}(t_{25}^{10})+2\tilde{\sigma}(t_{25}^{10})$ to a threshold.
When $\bar{s}(t_{0}(10))>\tilde{\mu}(t_{25}^{10})+2\tilde{\sigma}(t_{25}^{10})$ is satisfied, it is judged that a botnet is active at $t_{0}$, and an alert is issued.


\subsection{Usage of Graph Densities}
Although the above two criteria are determined from the change points of probability density functions of the GGM, they do not take advantage of the characteristics of the GGM graphs.
Mukai {\it et al.}~\cite{Mukai2} proposed a method to judge anomaly detection by visualizing a graph of the GGM.
Developing upon this idea, in our previous research~\cite{Han} we proposed a new criterion for judging abnormality using graph density.
Given $G=(V,E)$, where the number of nodes in the graph is $N(=|V|)$ and the number of edges is $|E|$, the graph density is defined as $d=|E|/N(N-1)$.
The graph density is the ratio of the actual number of edges to the number of edges of the complete graph.
If the graph density value is higher than those in the other time slots, it is considered that there are more cooperative relationships between source hosts than in the other time slots.
In our previous research, a statistical criterion for determining an abnormally high graph density value was determined and abnormalities were detected effectively.
At that time, a criterion for selecting the optimum regularization coefficient $r$ was proposed.

As an example, Figure~\ref{fig:density} shows a graph in which graph densities were obtained using actual darknet traffic data and arranged in chronological order.
$M$ is set to $6$, $T$ is set to 10 minutes, and the number of time slots is 47.
Figure~\ref{fig:graph1} corresponds to Graph 1 and 2 in Figure~\ref{fig:density}, respectively.
Graph 1 has 151 nodes and 1515 edges, and its graph density is about $0.0668$.
Graph 2 has 134 nodes and 134 edges, and its graph density is about $0.0075$.
When alert judgments are done using this data, detailed judgments calculation is omitted, but Graph 1, which has the highest graph density, can be obtained as an alert.
\begin{figure}[htbp]
	\includegraphics[width=8.0cm,clip]{./Materials/20151029_edit.eps}
	\caption{An example of graph density using undirected graphs}
  	\label{fig:density}
\end{figure}

\section{Proposed Method}
Since the method of our earlier work is effective but restrictive because its process is a batch learning type, and it may get alerts to be delayed for three days at maximum from the start of processing.
It cannot be used for real-time analysis.
In this research, we extend our method to enable an online processing and create an anomaly detection system to issue alerts in real-time.
In this section, we introduce a new alert judgment method, describe the online processing of anomaly-based detection using the alert judgment method, and describe its prototype implementation.
Finally we discuss the evaluation of calculation time reduction and parameter tunings.

\subsection{Anomaly-Based Alert Judgment Method for Online Processing}
We considered an anomaly detection-based method of discriminating alerts during online processing.
We could quantitatively quantize cooperative relationships among hosts in one time slot as graph density.
We desired to automatically identify time slots with abnormally high graph densities compared with the graph densities of other time slots by online processing.
For this purpose, we prepared graph densities of past $K$ time slots from the current time slot as a comparison object of the anomaly-based detection and considered a method of judging whether the current calculated graph density of a time slot is abnormal.
The method is described as follows.

Let $\bm{d} = (d_{1}, d_{2}, \cdots, d_{K})$ be a sequence in which graph densities of obtained time slots are arranged in descending order.
Next, let $\bm{d}_{(i)} = (d_{i}, d_{i+1},\cdots,d_{K})$, where $i$ is a natural number.
Let $\sigma^{2}_{(i)}$ be a variance of elements of $\bm{d}_{(i)}$.
At this time, assume that the maximum $i$ that satisfies $\sigma^{2}_{(i+1)}/\sigma^{2}_{(i)}<\theta (0\leq \theta \leq 1)$ is $i_{max}$ and set time slots corresponding to $(d_{1},d_{2},\cdots,d_{i_{max}})$ as an alert.
$\theta$ is usually set to $0.95$.
As well as the current calculated time slot by online processing, all of the past $K$ time slots are objects of alerts.
Finally, we look for a destination port with the highest ratio of unique hosts among the time slots judged as alerts and examine the port protocol and the hosts that sent the packets to the port.

Also, the sparsity of the estimated precision matrix from the graphical lasso differs depending on the value of regularization coefficient $r$.
That is, graph density values change in accordance with the value of $r$.
In the batch processing method~\cite{Han}, only one optimum value of $r$ was selected on the basis of input data.
However, we believed that was is important to issue an alert rather than deciding the optimal value of $r$ for online processing this time.
In this method, instead of selecting only one value of $r$, we calculate the graphical lasso by setting several values of $r$ in advance and issue an alert when a condition of an alert is satisfied for at least one value of $r$.


\subsection{Algorithm for Online Processing}
In this section, we outline the procedure for online processing.
Suppose that there is a sequence $\mathcal{D}=\{D_1, D_2, \cdots, D_K\}$ of data matrices obtained from time series of time slots and a set $d_{\mathcal{D}}^{(r)}=\{d^{(r)}_{D_1}, d^{(r)}_{D_2}, \cdots, d^{(r)}_{D_K}\}$ of $K$ graph densities calculated from $\mathcal{D}$ in advance.
$d^{(r)}_{D_i} (i \in \{1, 2, \cdots, K\})$ is the graph density for each predetermined regularization coefficient $r$ in the data matrix $D_i$.
It is assumed that the value of $r$ is preset like $r \in R ( =\{r_1, r_2, \cdots, r_s\} )$.
For example, preset $R=\{0.2, 0.4, \cdots, 1.8\}$.
For online processing, the matrix of an updated time slot is given by $D_t$.
The pseudocode for online processing is described in Algorithm~\ref{alg1}.

\begin{algorithm}[h]
\caption{Pseudocode for Online Processing}
\label{alg1}
\begin{algorithmic}
\FOR{$t = K+1, K+2, K+3, \cdots$}
	\STATE Read $D_t$
	\STATE Update $\mathcal{D} \longrightarrow \mathcal{D}=(D_{t-K}, \cdots, D_{K}, D_{t})$
	\FOR{$r$ in $R$}
		\STATE Compute $d_{D_t}^{(r)}$ from $D_t$
		\STATE Update $d_{\mathcal{D}}^{(r)} \longrightarrow d_{\mathcal{D}}^{(r)}=(d^{(r)}_{D_{t-K}}, \cdots, d^{(r)}_{D_K}, d^{(r)}_{D_t})$
		\STATE Compute an alert
		\vspace*{0.1cm}
		\IF{$d_{D_t}^{(r)}$ is judged as an alert}
			\vspace*{0.1cm}
			\STATE After determining the priority, output an alert
			\STATE Remove $d_{D_t}^{(r)}$ from $d_{\mathcal{D}}^{(r)}$
		\ENDIF
	\ENDFOR
\ENDFOR
\STATE Note: Updating $\mathcal{D}$ indicates that $D_t$ is linked to $\mathcal{D}$ and the oldest time slot in $\mathcal{D}$ is deleted.
Similarly, updating $d_{\mathcal{D}}^{(r)}$ indicates that $d_{D_t}^{(r)}$ is linked to $d_{\mathcal{D}}^{(r)}$ and the oldest graph density in $d_{\mathcal{D}}^{(r)}$ is deleted.
\end{algorithmic}
\end{algorithm}

When updating $\mathcal{D}$ and $d_{\mathcal{D}}^{(r)}$, each size is kept at $K$.
In this way, the number of time slots used for an alert determination is fixed like a sliding window.
With this procedure, an alert determination can be made sequentially from the updated data, and the computation cost has been reduced because only the graphical lasso needs to be calculated for the updated data.

\subsection{Prototype Implementation}
We implemented a prototype of the proposed method using the programming language R and its library ``glasso.''
In September 2017, we installed the program at the Cybersecurity Laboratory, NICT.
It is important to be able to processing input data online in real-time using the proposed method.
In this prototype, data obtained from seven different darknet sensors operated by NICT were used for input directly and were implemented successfully.
We used the following information from darknet packets: transmission times, source IP addresses, destination IP addresses (darknet host), and destination port numbers.
By setting up this prototype and operating it all the time, we were able to evaluate calculation time and parameter tunings in the next section.
Table~\ref{tab:sensor} shows details of IP addresses scales of each darknet sensors we used this time.

\begin{table}[htb]
  \begin{center}
    \caption{Details of IP addresses scales of each darknet sensors}
    \begin{tabular}{l|ccccccc} \hline
      Sensor & A & B & C & D & E & F & G \\ \hline
      Scales & 5 & 12 & 123 & 125 & 253 & 4,096 & 29,184 \\ \hline
    \end{tabular}
    \label{tab:sensor}
  \end{center}
\end{table}


\subsection{Calculation Time}
In this section, we evaluate the calculation time of the prototype.
The specifications the computer used for the evaluation at the Cybersecurity Laboratory, NICT include 16 GB of memory and an Intel Xeon E3-1230 v3 3.30 GHz CPU (4 cores, 8 threads).
To perform real-time processing with limited resources, it is necessary to finish a current calculation before updating the next time slot.
The largest computational complexity of the program is the graphical lasso algorithm $O(N^3)$~\cite{Witten}.
$N$ is the number of nodes in the graph, and in our problem, it corresponds to the number of source hosts in the processing target time slot.
In general, as the scale of darknets increases, $N$ also increases, so if the scale of darknets is large, we need to shorten the calculation time.

To shorten the calculation time, we devised the following measures.
\begin{itemize}
	\item Restrict the regularization coefficient, $r$.
	\item Ignore the third and fourth octets of IP addresses of source hosts.
	\item Select source hosts uniformly at random and limit the number of nodes, $N$.
\end{itemize}

However, there is a trade-off relationship with such restrictions.
Restring $r$ refers to reducing the number of its elements.
This restriction only reduces the number of trials of $r$, and it is thought that the result is less affected.
Ignoring octets means that IP addresses on the same subnet are regarded as one host.
In this case, a false negative may occur for hosts infected with malware on the same subnet.
Limiting the number of source hosts $N$ indicates that when $N$ exceeds the limit number, only part of the cooperative relationship between hosts is calculated.
Furthermore, as $N$ exceeds the limit number, the larger the difference between them, the lower the accuracy of the cooperative relationship estimation.
As the limitation of $N$ has the most influence on the results, it is necessary to devise a strategy where $N$ should be limited as little as possible.
In addition, since characteristics of darknet traffic data vary depending on its scale and the country in which the sensor is located, it is necessary to periodically adjust the above-mentioned parameters to be limited for each darknet.


\subsection{Parameter Tuning}
In this section, we evaluate the parameter tunings.
Much unknown malware is less cooperative than known malware and tends to be buried in other events.
If you expand parameters to capture unknown malware, alerts to known malware become excessive, so operation and management become hard.
It is necessary to set appropriate parameters so that such a situation does not occur.
These parameter tunings are empirically heuristic evaluation methods, in which the goal is to obtain about 10 to 20 daily alerts per darknet sensor and obtain alerts for as much unknown malware as possible.

\vspace*{0.3 cm}
\noindent
\textbf{A Length of Time Slot $T$}\\
On designing algorithms for real-time processing, an alert is delayed for the length of a time slot $T$ at its maximum, irrespective of the processing speed of the computer.
If you do not want a delay of processing so much, the $T$ should not be too long.
$T$ also needs to complete processing of the current time slot before the next time slot arrives.
Therefore, if the $T$ is shorter than 10 minutes, various restrictions have to be added before the calculation occurs.
Previous experience has proved that sufficiently good models and learnings cannot be done under such conditions.
As a result of conducting the preliminary experiments to determine the value of $T$, we set the value of $T$ to 10 minutes for all darknet traffic data.

\vspace*{0.3 cm}
\noindent
\textbf{A Threshold $\theta$ and the Number of Time Slots $K$}\\
There is a trade-off relationship between false positives (Type I error) and false negatives (Type I\hspace{-.1em}I error) in the above alert judgment equation $\sigma^{2}_{(i+1)}/\sigma^{2}_{(i)}<\theta$.
Parameters related to this trade-off relationship are the threshold $\theta$ of the alert judgment equation and the number of time slots $K$.
Decreasing $K$ or increasing $\theta$ raises the false positive rate, and conversely increasing $K$ or decreasing $\theta$ raises the false negative rate.
Since this trade-off relationship depends on input data, it does not quantitatively represented it at present.
However, we fixed $K = 432$ and adjusted the value of $\theta$ on the basis of practical experiences.
$K$ is fixed to 432 so that if $T$ is set 10 minutes, the total length of data used for an alert judgment is three days worth of data.
We set $\theta=0.95$ for all darknet traffic data.
However, with the parameter setting of the same condition, the number of average alerts greatly differs depending on the darknet sensor.
The smaller the observation host scale of the darknet sensor, the more alerts are obtained.
The reason is that a darknet sensor with a small observation host scale has an overall lower graph density average compared to that of a darknet sensor with a relatively large scale.
We plan to set $\theta$ differently for each darknet sensor in the future.


\vspace*{0.3 cm}
\noindent
\textbf{The Number of Sample $M$}\\
When converting time slots to forms of data matrix $D$, the estimated precision matrix changes depending on how many samples are needed to obtain the sample covariance matrix $S$.
The $M$ of Equations~(\ref{eq:d}) and~(\ref{eq:s}) represents this parameter.
This is an important parameter for model selection.
The sampling interval of the model is $T/M$.
Generally, it is said that as the number of samples increases, the model selection improves.

Figures~\ref{fig:M6},~\ref{fig:M10} and~\ref{fig:M20} are simulation results when $M$ was set to 6, 10, and 20, respectively, using the same darknet traffic data of 124 IP addresses.
The graph densities in these graphs are arranged in chronological order.
The red horizontal line is the baseline of alerts.
As $M$ increases, both overall graph density values, and the average decrease, indicating that the difference between the highest graph density and others become large.
This indicates that malicious activities can be easily judged from cooperative relationships among source hosts, and more true sample covariance matrices could be obtained.
In addition to this result, the same simulation was conducted for two different darknets of the same scale, and the same tendency was obtained.

However, just setting a large $M$ is not necessarily effective.
As the value of $M$ increases, the sampling interval of the model becomes shorter.
Since this method focuses on cooperativeness of malware, we want to ensure that one communication related to multiple hosts infected with malware includes as much data in one sample as possible.
Depending on environment, such as the scale of a darknet, the average time to observe one communication of malicious activities is different.
Currently, we set $M=6$ for all darknet traffic data, but in the future, we set $M$ to a larger value as the scale of darknets decreases, and set $M$ to a smaller value as the scale of darknets increases. ($6 \leq M \leq 20$)

\begin{figure}[htb]
	\includegraphics[width=8cm,clip]{./Materials/sample_6.eps}
	\caption{Simulation result when $M = 6, r=1.0$}
  	\label{fig:M6}
	\vspace*{0.3cm}
	\includegraphics[width=8cm,clip]{./Materials/sample_10.eps}
	\caption{Simulation result when $M = 10, r=0.6$}
  	\label{fig:M10}
	\vspace*{0.3cm}
	\includegraphics[width=8cm,clip]{./Materials/sample_20.eps}
	\caption{Simulation result when $M = 20, r=0.3$}
  	\label{fig:M20}
\end{figure}

\vspace*{0.3 cm}
\noindent
\textbf{Regularization Coefficient $r$}\\
We set the regularization coefficient $r \in R=\{0.1, 0.2, \cdots, 2\}$.
We determined that the value of $r$ can be fine-tuned even when rounded to six decimal points and the ``glasso'' program can still be run.
We confirmed whether results (alerts) obtained by finely adjusting the value of $r$ rounded to six decimal points will change.
As a result, a slight difference in graph density values occurred but was negligibly small.
The finer the interval, the longer the calculation time.
Furthermore, since the estimated precision matrix to exceed 1.8 becomes almost a zero matrix, we decided to increase in 0.2 intervals from 0.2 to 1.8 in the online processing.
That is, $r \in R=\{0.2, 0.4, \cdots, 1.8\}$.

As the number of zero elements in the estimated precision matrix increases, the calculation time decreases.
In other words, the computation time increases as the value of $r$ decreases, and conversely, the computation time decreases as the value of $r$ increases.
If we calculate by setting the value of $r$ from 0.2 to 1.8, increasing it in 0.2 intervals for large-scale darknet traffic data, we will have to strictly limit the parameters introduced in Section 5.4.
Since most alerts obtained with the value of $r$ being 0.2 or 0.4 can be obtained with those even at 0.6 for large-scale darknets, we set the value of $r$ from 0.6 to 1.8, increasing it in 0.2 intervals. $(r \in R=\{0.6, 0.8, \cdots, 1.8\}.)$

\section{Case Studies}
Since September 2017, we have been continuously operating our proposed method with darknet sensors located in seven different places operated by NICT.
Details of seven different sensors are shown in Table~\ref{tab:sensor}.
Regarding 4,096 scales sensor ``F'', we have properly got alerts of big events stably.
However, it was not able to get alerts stably on the other sensors.
There is a tendency to get a little more alerts on the small-scale sensor ``C'', ``D'' and ``E''.
Especially, there is a tendency to obtain quite a lot of alerts on the very small-scale sensor ``A'' and ``B''.
Many alerts with unknown meanings were also obtained with above sensors.
On the other hand, 29,184 scales sensor ``G'' tend not to be able to properly obtain alerts of even big events.
In this section, we introduce the preprocessing of data and instances of interest among alerts obtained from the continuous operation of our program since September 2017.


\subsection{Preprocessing of Data}
In this trial, only TCP packets to which a SYN flag was attached are collected.
And we pre-exclude packets arriving from known scanners which are for research and investigation purposes.
When a large number of packets constantly arrive at a specific TCP port, or when packets are constantly arriving from many hosts, that TCP ports are excluded.
For example, many packets for TCP port 22 (SSH), 23 (Telnet), and 80 (HTTP) are constantly observed.
Therefore, we intentionally exclude it considering the possibility that other packets would be buried due to those many packets.
In addition, we expect to get an unknown vulnerable TCP port as an alert by excluding known fragile TCP ports that we have frequently obtain as alerts.
In continuous operations, TCP ports 22, 23, 80, 443, 445, 1433, 2323, 3389, 5358, and 7547 were excluded from the preprocessing.

\subsection{Detection Instances Related to Mirai \\Variants (37215, 52869/TCP)}
In this section, we introduce detection instances of activities related to Mirai variants.
In addition, for comparing accuracy of alert detection, comparison with the method of~\cite{Mukai1}, in which a moving average score was calculated by the Kullback-Leibler divergence, was conducted.

Figure~\ref{fig:37215_1} shows an alert with a high density graph that was obtained at 12:30 on December 5, 2017, in Darknet ``A''.
In this figure, the horizontal axis shows the observation time in Japan Standard Time (JST), the vertical axis shows the value of the graph density, and the regularization coefficient $r$ was 1.4.
The scale of IP addresses of ``A'' is 5.
Therefore, traffic data observed from ``A'' are not large, and as $r$ increases, graph densities often become 0.
A graph density of 0 indicates the case that there are two or more nodes in the graph but there are no edges.
It means that our method can be applied to small-scale darknets.
Figure~\ref{fig:52869} shows that another alert with a high density graph was obtained at 20:50 on December 5, 2017, in the same darknet, which occurs about 8 hours after the alert shown in Figure~\ref{fig:37215_1}.
The regularization coefficient $r$ was 1.4.
Figure~\ref{fig:37215_2} shows an alert with a high density graph obtained at 8:50 on December 11, 2017, in Darknet ``C''.
The regularization coefficient $r$ was 1.6.
The scale of IP addresses of ``C'' is 123.
Compared to ``A'', ``C'' is large in scale to some extent, so the graph densities of all time periods are greater than 0 even when $r = 1.6$.

\begin{figure}[htb]
\begin{center}
	\includegraphics[width=8cm,clip]{./Materials/201712051230_1.4_d.eps}
	\caption{Graph densities from December 2 to 5, 2017 in Darknet ``A'' (12:30)}
  	\label{fig:37215_1}
	\vspace*{0.5cm}
	\includegraphics[width=8cm,clip]{./Materials/201712052050_1.4_d.eps}
	\caption{Graph densities from December 2 to 5, 2017 in Darknet ``A'' (20:50)}
  	\label{fig:52869}
	\vspace*{0.5cm}
	\includegraphics[width=8cm,clip]{./Materials/201712110850_1.6_d.eps}
	\caption{Graph densities from December 8 to 11, 2017 in Darknet ``C'' (8:50)}
  	\label{fig:37215_2}
\end{center}
\end{figure}

The alert shown in Figure~\ref{fig:52869} was issued against 52869/TCP and both alerts in Figures~\ref{fig:37215_1} and~\ref{fig:37215_2} were issued against 37215/ TCP.
With regard to 37215/TCP, we were able to obtain alerts not only for Darknets ``A'' and ``C'' but also for ``B'' and ``D'' at the same period of time.
Figure~\ref{fig:chart} shows a chronological chart of the number of unique hosts observed across our all darknets with about 300,000 IP addresses per one day.
On December 5, 2017, both TCP ports 37215 and 52869 were seen to have a rapidly increasing number of unique hosts.
This was demonstrated in Darknet ``A'' where an alert was obtained in real-time on that day for an event that occurred in relation to an abrupt increase in the number of hosts.

\begin{figure}[htb]
\begin{center}
	\includegraphics[width=8cm,clip]{./Materials/chart_37215_52869.eps}
	\caption{Chronological chart of the total number of unique hosts observed in our entire darknet per one day (37215, 52869/TCP)}
  	\label{fig:chart}
\end{center}
\end{figure}

Figures~\ref{fig:KL_50} and~\ref{fig:KL_56} are the results obtained using the moving average score as a comparative method.
The comparative targets of Figure~\ref{fig:KL_50} are Figures~\ref{fig:37215_1} and~\ref{fig:52869}, and the comparative target of Figure~\ref{fig:KL_56} is Figure~\ref{fig:37215_2}.
Since Figures~\ref{fig:37215_1} and~\ref{fig:52869} show the same date on the same darknet, the moving average score method was applied collectively at the time of Figure~\ref{fig:52869}.
Figure~\ref{fig:KL_50} shows the moving average scores by Kullback-Leibler divergence obtained from December 3 to 5, 2017, in Darknet ``A''.
The regularization coefficient $r$ was 1.4.
The black line is the moving average score, and the green line is the threshold.
If the moving average score exceeds the threshold, it becomes a red circle, and it becomes an alert in the moving average score method.
The blue dashed line indicates the time when an alert was obtained by the judgment method using the graph density.
In this method, it can be seen that many alerts were obtained after 12:00 on December 5, 2017.
On the other hand, the moving average score method does not get an alert.
Since this period of time is when the number of unique hosts to 37215/TCP and 52869/TCP increased rapidly, it is desirable to obtain a lot of alerts.
Figure~\ref{fig:KL_56} shows the moving average score by Kullback-Leibler divergence obtained from December 8 to 11, 2017, in Darknet ``C''.
The regularization coefficient $r$ was 1.6.
One alert was obtained by the judgment method using graph density at 8:50 on December 11, 2017, but no alerts were obtained by the moving average score method.
Alerts that were not triggered by the moving average score method could be obtained as alerts in the judgment method using graph density.
Alerts obtained during these times have characteristic malicious activities.

\begin{figure}[htb]
\begin{center}
	\includegraphics[width=8cm,clip]{./Materials/KL_50_201712051250_1.4.eps}
	\caption{Moving average score by KL divergence from December 3 to 5, 2017 in Darknet ``A''}
  	\label{fig:KL_50}
	\vspace*{0.5cm}
	\includegraphics[width=8cm,clip]{./Materials/KL_56_201712110850_1.6.eps}
	\caption{Moving average score by KL divergence from December 8 to 11, 2017 in Darknet ``C''}
  	\label{fig:KL_56}
\end{center}
\end{figure}

Details of the alerts obtained are described below.
The following items are related to 52869/TCP.
\begin{itemize}
	\item  A UPnP interface (52869/TCP) for a certain router product manufacturer ``Z'' is accessible from the Internet.
	\item Increased scanning of 52869/TCP in international darknet observation networks.
	\item A vulnerability exists in the miniigd SOAP service in Realtek SDK~\cite{Zeroday}
	\item In 52869/TCP communications, a payload that attacks command injection vulnerability (CVE-2014-8361~\cite{CVE}) has been seen.
	\item Executable files of Mirai variants were downloaded from the URL described in its source code.
\end{itemize}
For 37215/TCP, an attack similar to an attack directed to 52869/TCP has been confirmed.
This attack also targets the vulnerability of router products manufacturer ``Y'' in the same way.
The relevance between the scans for TCP ports 37215, 52869 and Mirai's variants were also mentioned in reports from multiple security vendors~\cite{Netlab2,Rise}.

\subsection{Detection Instances Related to ADB Miner (5555/TCP)}
In this section, we introduce detection instances of activities related to a mining botnet utilizing android ADB (Android Debug Bridge).
The moving average score was also calculated as a comparative method.
Figure~\ref{fig:5555_1} shows an alert with a high density graph that was obtained at 6:10 on February 4, 2018, in Darknet ``E''.
The regularization coefficient $r$ was 0.8.
Figure~\ref{fig:5555_2} shows an alert with a high density graph that was obtained at 7:30 on February 4, 2018, in Darknet ``F''.
The regularization coefficient $r$ was 0.6.

\begin{figure}[htb]
\begin{center}
	\includegraphics[width=8cm,clip]{./Materials/201802040610_0.8_d.eps}
	\caption{Graph densities from February 1 to 4, 2018 in Darknet ``E'' (6:10)}
  	\label{fig:5555_1}
	\vspace*{0.5cm}
	\includegraphics[width=8cm,clip]{./Materials/201802040730_0.6_d.eps}
	\caption{Graph densities from February 1 to 4, 2018 in Darknet ``F'' (7:30)}
  	\label{fig:5555_2}
\end{center}
\end{figure}

Both alerts in Figures~\ref{fig:5555_1} and~\ref{fig:5555_2} were issued against 5555/ TCP.
With regard to 5555/TCP, we were able to obtain alerts not only for Darknets ``E'' and ``F'' but also for all sensors (A, B, C, D, G) at the same period of time.
Figure~\ref{fig:chart_5555} shows a chronological chart of the number of unique hosts observed across our all darknets per one day.
On February 4, 2018, a TCP port 5555 was seen to have a rapidly increasing number of unique hosts.
This was demonstrated in Darknets ``E'' and ``F'' where alerts were obtained in real-time on that day for an event that occurred in relation to an abrupt increase in the number of hosts.

\begin{figure}[htb]
\begin{center}
	\includegraphics[width=8cm,clip]{./Materials/chart_5555.eps}
	\caption{Chronological chart of the total number of unique hosts observed in our entire darknet per one day (5555/TCP)}
  	\label{fig:chart_5555}
\end{center}
\end{figure}

Figures~\ref{fig:KL_5555_53} and~\ref{fig:KL_5555_61} are the results obtained using the moving average score as a comparative method.
The comparative target of Figure~\ref{fig:KL_5555_53} is Figure~\ref{fig:5555_1}, and the comparative target of Figure~\ref{fig:KL_5555_61} is Figure~\ref{fig:5555_2}.
Figure~\ref{fig:KL_5555_53} shows the moving average score by Kullback-Leibler divergence obtained from February 1 to 4, 2018, in Darknet ``E''.
The regularization coefficient $r$ was 0.8.
Figure~\ref{fig:KL_5555_61} shows the moving average score by Kullback-Leibler divergence obtained from February 1 to 4, 2018, in Darknet ``F''.
The regularization coefficient $r$ was 0.6.
In Figures~\ref{fig:KL_5555_53} and~\ref{fig:KL_5555_61}, it can be seen that the moving average method can not detect in real-time on February 4, 2018.

\begin{figure}[htb]
\begin{center}
	\includegraphics[width=8cm,clip]{./Materials/KL_53_201802040610_0.8.eps}
	\caption{Moving average score by KL divergence from February 1 to 4, 2018 in Darknet ``E''}
  	\label{fig:KL_5555_53}
	\vspace*{0.5cm}
	\includegraphics[width=8cm,clip]{./Materials/KL_61_201802040730_0.6.eps}
	\caption{Moving average score by KL divergence from February 1 to 4, 2018 in Darknet ``F''}
  	\label{fig:KL_5555_61}
\end{center}
\end{figure}

Details of the alerts obtained are described below.
The following items are related to 5555/TCP.
\begin{itemize}
	\item  ADB.Miner a mining botnet utilizing android ADB (Android Debug Bridge) is spreading via 5555/TCP.
	\item It is seen in large quantity from February 4 and about 16,000 hosts could be seen at the peak from NICTER's darknets. Since then, the attack continues while maintaining the scale.
	\item According to Netlab 360 report~\cite{Netlab1}, they detected at 15:00 on February 3 (GMT +8) by their system and the earliest time of the infection could be traced back to January 31.
	\item It infects when 5555/TCP (ADB debugging interface) is open and mainly its target is Android devices.
	\item Worm infection: Infected devices will initiate a network scan on 5555/TCP, and attempt to execute ADB commands for newly infecting worm like.
	\item XMR Mining: After infection, it will dig XMR tokens.
	\item In addition, this worm borrows code from Mirai's SYN scanning module for efficiency. This is the first case where the Mirai's code was seen on Android bots.
	\item In the case of Japan, there were many infections when using Android devices from overseas manufacturers and a specific mobile SIM card.
\end{itemize}


\subsection{Detection Instances Related to Hajime \\Variants (8291, 2000/TCP)}
In this section, we introduce detection instances of activities related to Hajime botnet variants.
The moving average score was also calculated as a comparative method.
Figure~\ref{fig:8291_1} shows an alert with a high density graph that was obtained at 1:00 on March 25, 2018, in Darknet ``F''.
The regularization coefficient $r$ was 0.6.
Figure~\ref{fig:8291_2} shows an alert with a high density graph that was obtained at 12:50 on March 27, 2018, in Darknet ``G''.
The regularization coefficient $r$ was 0.6.
Figure~\ref{fig:2000_1} shows an alert with a high density graph that was obtained at 9:30 on March 31, 2018, in Darknet ``D''.
The regularization coefficient $r$ was 1.4.
Figure~\ref{fig:2000_2} shows an alert with a high density graph that was obtained at 9:50 on March 31, 2018, in Darknet ``C''.
The regularization coefficient $r$ was 0.8.

\begin{figure}[htb]
\begin{center}
	\includegraphics[width=8cm,clip]{./Materials/201803250100_0.6_d.eps}
	\caption{Graph densities from March 22 to 25, 2018 in Darknet ``F'' (1:00)}
  	\label{fig:8291_1}
	\vspace*{0.5cm}
	\includegraphics[width=8cm,clip]{./Materials/201803271250_1.4_d.eps}
	\caption{Graph densities from March 24 to 27, 2018 in Darknet ``G'' (12:50)}
  	\label{fig:8291_2}
\end{center}
\end{figure}

\begin{figure}[htb]
\begin{center}
	\includegraphics[width=8cm,clip]{./Materials/201803310930_1.4_d.eps}
	\caption{Graph densities from March 28 to 31, 2018 in Darknet ``D'' (9:30)}
  	\label{fig:2000_1}
	\vspace*{0.5cm}
	\includegraphics[width=8cm,clip]{./Materials/201803310950_0.8_d.eps}
	\caption{Graph densities from March 28 to 31, 2018 in Darknet ``C'' (9:50)}
  	\label{fig:2000_2}
\end{center}
\end{figure}

Both alerts in Figures~\ref{fig:8291_1} and~\ref{fig:8291_2} were issued against 8291/ TCP and both alerts in Figures~\ref{fig:2000_1} and~\ref{fig:2000_2} were issued against 2000/TCP.
With regard to 8291/TCP and 2000/TCP, we were able to obtain both two alerts of TCP ports 8291 and 2000 from all sensors at the same period of time.
Figure~\ref{fig:chart_8291_2000} shows a chronological chart of the number of unique hosts observed across our all darknets per one day.
On March 25, 2018, a TCP port 8291 was seen to have a rapidly increasing number of unique hosts and also on March 31, 2018, a TCP port 2000 was seen to have a rapidly increasing in the same way.

\begin{figure}[htb]
\begin{center}
	\includegraphics[width=8cm,clip]{./Materials/chart_8291_2000.eps}
	\caption{Chronological chart of the total number of unique hosts observed in our entire darknet per one day (8291, 2000/TCP)}
  	\label{fig:chart_8291_2000}
\end{center}
\end{figure}

Figures~\ref{fig:KL_8291_61},~\ref{fig:KL_2000_58} and~\ref{fig:KL_2000_56} are the results obtained using the moving average score as a comparative method.
The comparative targets of Figures~\ref{fig:KL_8291_61},~\ref{fig:KL_2000_58} and ~\ref{fig:KL_2000_56} are Figures~\ref{fig:8291_1},~\ref{fig:KL_2000_58} and~\ref{fig:KL_2000_56}, respectively.
Figure~\ref{fig:KL_8291_61} shows the moving average score by Kullback-Leibler divergence obtained from March 22 to 25, 2018, in Darknet ``F''.
The regularization coefficient $r$ was 0.6.
Figure~\ref{fig:KL_2000_58} shows the moving average score by Kullback-Leibler divergence obtained from March 28 to 31, 2018, in Darknet ``D''.
The regularization coefficient $r$ was 1.4.
Figure~\ref{fig:KL_2000_56} shows the moving average score by Kullback-Leibler divergence obtained from March 28 to 31, 2018, in Darknet ``C''.
The regularization coefficient $r$ was 0.8.
In Figure~\ref{fig:KL_8291_61}, it can be seen that the moving average method can not detect in real-time on March 25, 2018.
However, in Figures~\ref{fig:KL_2000_58} and~\ref{fig:KL_2000_56}, the moving average method detects about one hour earlier than graph densities.
As you can see, the moving average method may detect earlier than graph densities in some cases, but from other above cases, you can see that there are many misses (false negatives).

\begin{figure}[htb]
\begin{center}
	\includegraphics[width=8cm,clip]{./Materials/KL_61_201803250100_0.6.eps}
	\caption{Moving average score by KL divergence from March 22 to 25, 2018 in Darknet ``F''}
  	\label{fig:KL_8291_61}
	\vspace*{0.5cm}
	\includegraphics[width=8cm,clip]{./Materials/KL_58_201803310930_1.4.eps}
	\caption{Moving average score by KL divergence from March 28 to 31, 2018 in Darknet ``D''}
  	\label{fig:KL_2000_58}
	\includegraphics[width=8cm,clip]{./Materials/KL_56_201803310950_0.8.eps}
	\caption{Moving average score by KL divergence from March 28 to 31, 2018 in Darknet ``C''}
  	\label{fig:KL_2000_56}
\end{center}
\end{figure}

Details of the alerts obtained are described below.
The following items are related to TCP ports 8291 and 2000.
\begin{itemize}
	\item TCP ports 8291 and 2000 scanning events are caused by a Hajime botnet variant targeting vulnerabilities of router products manufacturer ``X''.
	\item 8291/TCP increased sharply from March 25, but attacks with the same behaviors moved from March 31 to 2000/TCP.
	\item As a feature of Hajime, C\&C communication using BitTorrent's P2P protocol is performed and it supports only ARM and MIPS architecture. Also, the source code is not published and there are few variants.
	\item If the TCP port 8291 or 2000 is open, then it tries to infect by accessing following common web ports: 80, 81, 82, 8080, 8081, 8082, 8089, 8181, 8880~\cite{Radware}.
	\item It exploits known vulnerabilities of an operating system of router (ChimayRed HTTP exploit, SMB buffer-overflow vulnerability (CVE-2018-7445~\cite{CVE2})) as well as password brute-forcing.
\end{itemize}


\section{Conclusion}
We were able to process an online anomaly detection method using the sparse structure learning algorithm, graphical lasso, and an alert judgment method by graph density.
The methods were put to practical uses, and the calculation times were shortened and parameter tunings were evaluated.
We were able to introduce instances of activities related to Mirai variants, ADB Miner and Hajime variants from results detected from our program's continuous operation.
We obtained alerts in real-time as the number of hosts increased sharply.
Also, we found that our method is applicable to small-scale darknets.
However, there is a tendency that the number of alerts tends to increase in small-scale darknets, and in large-scale darknets, there are many restrictions and it tends not to obtain alerts appropriately.

We anticipate that we can obtain alerts at an earlier stage by taking countermeasures.
We will determine the optimal parameters for each darknet to obtain alerts regardless of its scale in our next step.
Although parameter tunings in this paper were mainly based on experience, in future works, it is necessary to quantitatively and objectively evaluate them.
In particular, we plan to make a probabilistic evaluation by fixing the parameters other than $M$ and calculating the ratio of false positives and false negatives using multiple $M$.
We also plan to evaluate $\theta$ in the same way with the other fixed parameters as well.
On the basis of such an evaluation, it is also necessary to obtain the accuracy of the all alerts, and the accuracy of our method.
To achieve this, we need correct labels, but these would need to be manually labeled by the experts in charge of NICTER's operation.
We intend to apply this method to other darknet sensors.
Up to now, filtering ports in preprocessing was done manually, but automatic processing is also one of our future works.
In addition, it will be tested not only for TCP ports but also UDP ports.


%\section*{Acknowledgments}
%We appreciate the feedback offered by everyone of Cyber Security Laboratory, NICT.
%Our work was partially supported by ``PRACTICE : Proactive Response Against Cyber-Attacks Through International Collaborative Exchange'' administered by the Ministry of Internal Affairs and Communications.

\begin{thebibliography}{100}

\bibitem{Akiyama}
M. Akiyama, T. Kawamoto, M. Shimamura, T. Yokoyama, Y. Kadobayashi, and S. Yamaguchi. A Proposal of Metrics for Botnet Detection Based on Its Cooperative Behavior. In {\it Proceedings of the SAINT 2007 Internet Measurement Technology and its Applications to Building Next Generation Internet Workshop}, 2007.

\bibitem{Ali}
S. H. A. Ali, S. Ozawa, T. Ban, J. Nakazato, and J. Shimamura. A Neural Network Model for Detecting DDoS Attacks Using Darknet Traffic Features. In {\it 2016 International Joint Conference on Neural Networks (IJCNN), IEEE}, 2016.

\bibitem{Bailey}
M. Bailey, E. Cooke, F. Jahanian, J. Nazario, and D. Watson. The Internet Motion Sensor-A Distributed Blackhole Monitoring System. In {\it NDSS}, 2005.

\bibitem{Bailey2}
M. Bailey, E. Cooke, F. Jahanian, A. Myrick, and S. Sinha. Practical darknet measurement. In {\it 40th Annual Conference on Information Sciences and Systems, IEEE}, 2006.

\bibitem{Ban}
T. Ban, L. Zhu, J. Shimamura, S. Pang, D. Inoue, and K. Nakao. Detection of Botnet Activities Through the Lens of a Large-Scale Darknet. {\it In International Conference on Neural Information Processing, Springer}, 2017.

\bibitem{Banerjee}
O. Banerjee, L. E. Ghaoui, and A. d'Aspremont. Model Selection Through Sparse Maximum Likelihood Estimation for Multivariate Gaussian or Binary Data. {\it Journal of Machine learning research, 9(Mar)}, 2008.

\bibitem{Choi}
S. Choi, J. Song, S. Kim, and S. Kim. A Model of Analyzing Cyber Threats Trend and Tracing Potential Attackers Based on Darknet Traffic. {\it Security and Communication Networks}, 7(10), 2014.

\bibitem{CVE}
CVE-2014-8361 Detail. \url{https://nvd.nist.gov/vuln/detail/CVE-2014-8361}, [Accessed January 2018].

\bibitem{CVE2}
CVE-2018-7445 Detail. \url{https://nvd.nist.gov/vuln/detail/CVE-2018-7445}, [Accessed April 2018].

\bibitem{CyberLab}
Cybersecurity Laboratory, Cybersecurity Research Institute
National Institute of Information and Communications Technology. NICTER Analysis Report 2016. \url{http://www.nict.go.jp/en/cyber/4otfsk00003rpx3e-att/NICTER_report_2016.pdf}, [Accessed December 2017].

\bibitem{Dempster}
A.P. Dempster. Covariance Selection. {\it Biometrics}, 1972.

\bibitem{Falt}
J. Falt, and S. D. Blostein. A Bayesian Approach to Two-Sided Quickest Change Detection. {\it IEEE International Symoposium on Information Theory}, 2014.

\bibitem{Feily}
M. Feily, A. Shahrestani, and S. Ramadass. A Survey of Botnet and Botnet Detection. In {\it Third International Conference on Emerging Security Information, Systems and Technologies, IEEE}, 2009.

\bibitem{Friedman}
J. Friedman, T. Hastie, and R. Tibshirani. Sparse Inverse Covariance Estimation with the Graphical Lasso. {\it Biostatistics}, 9(3), 2008.

\bibitem{Garcia}
S. Garc\'{i}a, A. Zunino, and M. Campo. Survey on Network‐based Botnet Detection Methods. {\it Security and Communication Networks}, 7(5), 2014.

\bibitem{Garcia2}
S. Garc\'{i}a, A. Zunino, and M. Campo. Botnet Behavior Detection Using Network Synchronism. In {\it Privacy, Intrusion Detection and Response: Technologies for Protecting Networks}, 2011.

\bibitem{Gu}
G. Gu, J. Zhang, and W. Lee. BotSniffer: Detecting Botnet Command and Control Channels in Network Traffic. In {\it Proceedings of the 15th Network and Distributed System Security Symposium (NDSS)}, 2008.

\bibitem{Gu2}
G. Gu, R. Perdisci, J. Zhang, and W. Lee. BotMiner: Clustering Analysis of Network Traffic for Protocol-and Structure-Independent Botnet Detection. In {\it USENIX security symposium}, 2008.

\bibitem{Hamasaki}
H. Hamasaki, M. Kawakita, J. Takeuchi, K. Yoshioka, D. Inoue, M. Etoh, and K. Nakao. Proposal of Botnet Detection Based on Structure Learning and Its Application to Darknet Data. {\it Symposium on Cryptography and Information Security}, 2011. (in Japanese)

\bibitem{Han}
C. Han, K. Kono, S. Tanaka, M. Kawakita, and J. Takeuchi. Botnet Detection Using Graphical Lasso with Graph Density. {\it In International Conference on Neural Information Processing, Springer}, 2016.

\bibitem{Ide}
T. Ide, A.C. Lozano, N. Abe, and Y, Liu. Proximity-Based Anomaly Detection Using Sparse Structure Learning. {\it SDM}, 2009.

\bibitem{McCarty}
B. McCarty. Botnets: Big and Bigger. {\it IEEE Security \& Privacy}, 99(4), 2003.

\bibitem{Meinshausen}
N. Meinshausen, and P. Buhlmann. High-Dimensional Graphs and Variable Selection with the Lasso. {\it The annals of statistics}, 2006.

\bibitem{Mukai1}
S. Mukai, Y. Kawamura, M. Kawakita, and J. Takeuchi. Performance Evaluation of Botnet Detection Method Using a Sparse Structure Learning. {\it Symposium on Cryptography and Information Security}, 2015. (in Japanese)

\bibitem{Mukai2}
S. Mukai, Y. Kawamura, M. Kawakita, and J. Takeuchi. Botnet Detection Using Anomaly Detection Based on Sparse Structure Learning. {\it IEICE Tech. Rep., vol. 114, no. 471, ISEC2014-105}, 2015. (in Japanese)

\bibitem{Nakao}
K. Nakao, D. Inoue, M. Eto, and K. Yoshioka. Practical Correlation Analysis Between Scan and Malware Profiles Against Zero-Day Attacks Based on Darknet Monitoring. {\it IEICE TRANSACTIONS on Information and Systems}, 92(5), 2009.

\bibitem{Netlab1}
Netlab 360, ADB.Miner: More Information. \url{https://blog.netlab.360.com/adb-miner-more-information-en/}, [Accessed February 2018].

\bibitem{Netlab2}
Netlab 360, Warning: Satori, a Mirai Branch Is Spreading in Worm Style on Port 37215 and 52869. \url{http://blog.netlab.360.com/warning-satori-a-new-mirai-variant-is-}\\\url{spreading-in-worm-style-on-port-37215-}\\\url{and-52869-en/}, [Accessed January 2018].

\bibitem{NICTERWEB}
NICTERWEB. \url{http://www.nicter.jp/}, [Accessed December 2017].

\bibitem{Radware}
Radware, The Mikrotik RouterOS-Based Botnet. \url{https://security.radware.com/ddos-threats-attacks/threat-advisories-attack-reports/mikrotik-botnet/}, [Accessed April 2018].

\bibitem{Rise}
Rise of One More Mirai Worm Variant. \url{https://blog.fortinet.com/2017/12/12/rise-of-one-more-mirai-worm-variant}, [Accessed January 2018].

\bibitem{Strayer}
W. T. Strayer, R. Walsh, C. Livadas, and D. Lapsley. Detecting Botnets with Tight Command and Control. In {31st IEEE Conference on Local Computer Networks}, 2006.

\bibitem{Tibshirani}
R. Tibshirani. Regression Shrinkage and Selection via the Lasso: a Retrospective. {\it Journal of the Royal Statistical Society: Series B (Statistical Methodology), 73(3)}, 2011.

\bibitem{Witten}
D. Witten, J. Friedman, and N. Simon. New Insights and Faster Computations for the Graphical Lasso. {\it Journal of Computational and Graphical Statistics}, 20(4), 2011.

\bibitem{Yamauchi}
S. Yamauchi, M. Kawakita, and J. Takeuchi. Botnet Detection Based on Non-Negative Matrix Factorization and the MDL Principle. In {\it International Conference on Neural Information Processing, Springer}, 2012.

\bibitem{Zeroday}
Zero Day Initiative, Realtek SDK miniigd AddPortMapping SOAP Action Command Injection Remote Code Execution Vulnerability. \url{https://www.zerodayinitiative.com/advisories/ZDI-15-155/}, [Accessed December 2018].

\end{thebibliography}

\end{document}
